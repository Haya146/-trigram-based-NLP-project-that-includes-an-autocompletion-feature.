# Trigram Language Model with Perplexity and Laplace Smoothing NLP

**This project implements a trigram language model using Natural Language Processing (NLP) techniques in Python. It leverages the NLTK library for tokenization and text processing, with a focus on generating and analyzing trigrams (sequences of three consecutive words). The model calculates the probability of trigrams using Laplace smoothing to handle unseen sequences and improve accuracy.**

Key Features:

* Trigram Generation: Creates sequences of three words from a given text corpus.
* Trigram Probability Calculation: Estimates trigram probabilities based on observed frequencies, applying Laplace smoothing to handle unseen trigrams.
* Perplexity Calculation: Measures the model's performance by calculating the perplexity for a given sentence, indicating how well the model predicts the next word.
* Streamlit Application: Provides an interactive web interface where users can input a sentence and receive predictions for the next word, based on the model's trigram probabilities.


This project demonstrates the power of n-grams in language modeling and provides a hands-on application for text generation and prediction.






